## GCP Services Used in This Project

This project leverages several Google Cloud Platform services to build a robust MLOps pipeline:

1.  **Google Compute Engine (GCE):**
    *   **Purpose:** Hosts the persistent MLflow Tracking Server.
    *   **Instance Details:** A small VM (e.g., `mlflow-server-vm`, type `e2-micro`) running Debian Linux.
    *   **Why:** Provides a stable, network-accessible environment to run the `mlflow server` process continuously, making the MLflow UI, experiment tracking, and model registry available to all users, CI/CD pipelines, and deployed applications. It uses an attached service account with necessary permissions.

2.  **Google Cloud SQL (for PostgreSQL):**
    *   **Purpose:** Serves as the **Backend Store** for the MLflow Tracking Server.
    *   **Instance Details:** A managed PostgreSQL instance (e.g., `mlflow-db-instance`) containing a dedicated database (e.g., `mlflow_backend_db`).
    *   **Why:** MLflow requires a relational database to store metadata about experiments, runs, parameters, metrics, registered models, versions, and stages. Cloud SQL provides a managed, reliable, and scalable database solution, removing the need to manage database servers manually. Connection from the GCE VM is secured using the Cloud SQL Auth Proxy.

3.  **Google Cloud Storage (GCS):**
    *   **Purpose 1: DVC Remote Storage:**
        *   Bucket: e.g., `gs://minedvcstore-1` (with a `dvc-store` prefix).
        *   Stores actual data files (`reviews.csv`) and DVC-tracked model artifacts (`sentiment_model.joblib`, `tfidf_vectorizer.joblib`) versioned by DVC.
        *   **Why:** Provides a scalable and durable remote backend for DVC, enabling data/model sharing and versioning across environments (local, CI).
    *   **Purpose 2: MLflow Artifact Store:**
        *   Bucket: e.g., `gs://sentiment-mlops-mlflow-artifacts`.
        *   Stores artifacts logged by MLflow during experiment runs, such as model files (separate copies from DVC's), plots (`confusion_matrix.png`), and other arbitrary files. The MLflow Model Registry points to model artifacts stored here.
        *   **Why:** GCS is an ideal place to store these potentially large binary artifacts generated by MLflow runs, separate from the metadata in Cloud SQL.

4.  **Google Artifact Registry:**
    *   **Purpose:** Stores the Docker container images built by the CI/CD pipeline.
    *   **Repository Details:** A Docker repository (e.g., `mlops-images` in region `europe-west1`) within Artifact Registry (e.g., `europe-west1-docker.pkg.dev/crested-grove-240711/mlops-images`).
    *   **Why:** Provides a secure, private (or public) registry for Docker images, tightly integrated with other GCP services like Cloud Run. It's Google's recommended container registry.

5.  **Google Cloud Run:**
    *   **Purpose:** Hosts and serves the containerized Flask API (`sentiment-analysis-api`).
    *   **Service Details:** A fully managed, serverless platform that runs stateless containers. It automatically scales based on traffic.
    *   **Why:** Simplifies deployment and management of containerized web applications, allowing a focus on code rather than infrastructure. It integrates with Artifact Registry for image deployment and Cloud Monitoring/Logging for observability.

6.  **IAM (Identity and Access Management):**
    *   **Purpose:** Manages permissions for users and service accounts to access GCP resources.
    *   **Usage:**
        *   A dedicated service account (e.g., `gcp-creds3.json`'s account) is used by local DVC, GitHub Actions, and the GCE VM.
        *   This service account has specific roles granted (e.g., `Storage Object Admin` on GCS buckets, `Cloud SQL Client`, `Artifact Registry Writer`, `Cloud Run Admin`, `Service Account User`) to perform its tasks according to the principle of least privilege.
    *   **Why:** Ensures secure access to cloud resources.

7.  **Google Cloud Monitoring & Logging:**
    *   **Purpose:** Provides observability for the deployed Cloud Run service.
    *   **Usage:** Automatically collects metrics (request count, latency, errors, utilization) and logs (request logs, container logs) for Cloud Run. Used to set up basic alerts.
    *   **Why:** Essential for understanding the health, performance, and behavior of the deployed application.